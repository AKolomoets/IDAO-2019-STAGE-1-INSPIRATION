{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import scoring\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "\n",
    "SIMPLE_FEATURE_COLUMNS = [\n",
    "    'ncl[0]', 'ncl[1]', 'ncl[2]', 'ncl[3]', 'avg_cs[0]',\n",
    "    'avg_cs[1]', 'avg_cs[2]', 'avg_cs[3]', 'ndof', 'MatchedHit_TYPE[0]',\n",
    "    'MatchedHit_TYPE[1]', 'MatchedHit_TYPE[2]', 'MatchedHit_TYPE[3]',\n",
    "    'MatchedHit_X[0]', 'MatchedHit_X[1]', 'MatchedHit_X[2]',\n",
    "    'MatchedHit_X[3]', 'MatchedHit_Y[0]', 'MatchedHit_Y[1]',\n",
    "    'MatchedHit_Y[2]', 'MatchedHit_Y[3]', 'MatchedHit_Z[0]',\n",
    "    'MatchedHit_Z[1]', 'MatchedHit_Z[2]', 'MatchedHit_Z[3]',\n",
    "    'MatchedHit_DX[0]', 'MatchedHit_DX[1]', 'MatchedHit_DX[2]',\n",
    "    'MatchedHit_DX[3]', 'MatchedHit_DY[0]', 'MatchedHit_DY[1]',\n",
    "    'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[0]',\n",
    "    'MatchedHit_DZ[1]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]',\n",
    "    'MatchedHit_T[0]', 'MatchedHit_T[1]', 'MatchedHit_T[2]',\n",
    "    'MatchedHit_T[3]', 'MatchedHit_DT[0]', 'MatchedHit_DT[1]',\n",
    "    'MatchedHit_DT[2]', 'MatchedHit_DT[3]', 'Lextra_X[0]', 'Lextra_X[1]',\n",
    "    'Lextra_X[2]', 'Lextra_X[3]', 'Lextra_Y[0]', 'Lextra_Y[1]',\n",
    "    'Lextra_Y[2]', 'Lextra_Y[3]', 'NShared', 'Mextra_DX2[0]',\n",
    "    'Mextra_DX2[1]', 'Mextra_DX2[2]', 'Mextra_DX2[3]', 'Mextra_DY2[0]',\n",
    "    'Mextra_DY2[1]', 'Mextra_DY2[2]', 'Mextra_DY2[3]', 'FOI_hits_N', 'PT', 'P'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'PT', 'NShared', 'ncl[0]', 'Delta_D_norm[3]', 'Delta_D_norm[0]',\n",
    "    'Delta_X_norm[1]', 'Delta_D_norm[1]', 'Delta_D_norm[2]', 'ncl[2]',\n",
    "    'Delta_X_norm[0]', 'ncl[3]', 'Mextra_DX[3]', 'MatchedHit_R[1]', 'P', 'ncl[1]',\n",
    "    'D_Delta_R[1]', 'FOI_hits_N', 'Lextra_Y[0]', 'Delta_R[3]', 'avg_cs[0]',\n",
    "    'avg_cs[1]', 'MatchedHit_R[3]', 'MatchedHit_T[2]', 'Delta_X_norm[3]',\n",
    "    'D_Delta_R[2]', 'avg_cs[3]', 'Delta_L_norm[1]', 'MatchedHit_Y[1]',\n",
    "    'MatchedHit_Y[3]', 'MatchedHit_DT[0]', 'MatchedHit_R[2]', 'Delta_Y_norm[0]',\n",
    "    'MatchedHit_TYPE[1]', 'MatchedHit_Z[3]', 'MatchedHit_T[3]', 'Delta_L_norm[0]',\n",
    "    'MatchedHit_T[1]', 'Delta_L_norm[2]', 'MatchedHit_X[3]', 'MatchedHit_TYPE[0]',\n",
    "    'D_Delta_X[3]', 'Delta_X_norm[2]', 'MatchedHit_DZ[3]', 'MatchedHit_Z[2]',\n",
    "    'MatchedHit_Z[1]', 'MatchedHit_Y[0]', 'MatchedHit_Z[0]', 'Delta_R_norm[3]',\n",
    "    'avg_cs[2]', 'MatchedHit_DZ[2]', 'D_Delta_X[1]', 'Delta_Y[2]'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 34s, sys: 18.4 s, total: 8min 52s\n",
      "Wall time: 8min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_features(sample):\n",
    "    feature_sets = dict()\n",
    "\n",
    "    # ------ Радиусы и неопределенности ------\n",
    "    \n",
    "    # радиусы столкновений и неопределенности координат\n",
    "    for stage in [0,1,2,3]:\n",
    "        sample[f'MatchedHit_R[{stage}]'] = np.sqrt(sample[f'MatchedHit_X[{stage}]']**2 + sample[f'MatchedHit_Y[{stage}]']**2)\n",
    "        sample[f'Lextra_R[{stage}]'] = np.sqrt(sample[f'Lextra_X[{stage}]']**2 + sample[f'Lextra_Y[{stage}]']**2)\n",
    "        sample[f'MatchedHit_DR[{stage}]'] = np.sqrt(sample[f'MatchedHit_DX[{stage}]']**2 + sample[f'MatchedHit_DY[{stage}]']**2)\n",
    "        sample[f'Mextra_DR2[{stage}]'] = sample[f'Mextra_DX2[{stage}]'] + sample[f'Mextra_DY2[{stage}]']\n",
    "    \n",
    "    # расчетная неопределенность координат и радиуса (извлекаем корни)\n",
    "    for stage in [0,1,2,3]:\n",
    "        for ax in ['X', 'Y', 'R']:\n",
    "            sample[f'Mextra_D{ax}[{stage}]'] = np.sqrt(sample[f'Mextra_D{ax}2[{stage}]'])\n",
    "    \n",
    "    # ------ Отклонения расчетных и измеренных показателей ------\n",
    "\n",
    "    # неопределенность разности измеренных и расчетных показателей (нормировочные коэффициенты)\n",
    "    for stage in [0,1,2,3]:\n",
    "        for ax in ['X', 'Y', 'R']:\n",
    "            sample[f'D_Delta_{ax}[{stage}]'] = np.sqrt(sample[f'MatchedHit_D{ax}[{stage}]']**2 + sample[f'Mextra_D{ax}2[{stage}]'])\n",
    "    \n",
    "    # отклонение координат и радиуса\n",
    "    for stage in [0,1,2,3]:\n",
    "        for ax in ['X', 'Y', 'R']:\n",
    "            sample[f'Delta_{ax}[{stage}]'] = sample[f'MatchedHit_{ax}[{stage}]'] - sample[f'Lextra_{ax}[{stage}]']\n",
    "            sample[f'Delta_{ax}_norm[{stage}]'] = sample[f'Delta_{ax}[{stage}]'].abs()/sample[f'D_Delta_{ax}[{stage}]']\n",
    "\n",
    "    # расстояние\n",
    "    for stage in [0,1,2,3]:\n",
    "        sample[f'Delta_D[{stage}]'] = np.sqrt(sample[f'Delta_X[{stage}]']**2 + sample[f'Delta_Y[{stage}]']**2)\n",
    "        sample[f'Delta_D_norm[{stage}]'] = sample[f'Delta_D[{stage}]']/sample[f'D_Delta_R[{stage}]']\n",
    "\n",
    "    # продольное отклонение\n",
    "    for stage in [0,1,2,3]:\n",
    "        sample[f'Delta_L[{stage}]'] = np.sqrt((sample[f'Delta_D[{stage}]']**2 - sample[f'Delta_R[{stage}]']**2).clip(0))\n",
    "        sample[f'Delta_L_norm[{stage}]'] = sample[f'Delta_L[{stage}]']/sample[f'D_Delta_R[{stage}]']\n",
    "\n",
    "types = dict(zip(SIMPLE_FEATURE_COLUMNS+['weight'], repeat(np.float32)))\n",
    "types['id'] = np.int64\n",
    "types['label'] = np.int64\n",
    "        \n",
    "train = pd.concat([\n",
    "    pd.read_csv(os.path.join(DATA_PATH, \"train_part_%i.csv.gz\" % i),\n",
    "                usecols = SIMPLE_FEATURE_COLUMNS + ['id', 'label', 'weight'],\n",
    "                index_col='id', dtype=types)\n",
    "    for i in (1,2)], axis=0, ignore_index=True)\n",
    "\n",
    "test_public = pd.read_csv(os.path.join(DATA_PATH, \"test_public.csv.gz\"),\n",
    "                          usecols = SIMPLE_FEATURE_COLUMNS + ['id'],  \n",
    "                          index_col='id', dtype=types)\n",
    "\n",
    "test_private = pd.read_csv(os.path.join(DATA_PATH, 'test_private_v3_track_1.csv.gz'),\n",
    "                           usecols = SIMPLE_FEATURE_COLUMNS + ['id'],\n",
    "                           index_col='id', dtype=types)\n",
    "\n",
    "build_features(train)\n",
    "build_features(test_public)\n",
    "build_features(test_private)\n",
    "\n",
    "train.to_csv('track1_train.csv', columns=features+['label', 'weight'], index_label='id')\n",
    "test_public.to_csv('track1_test_public.csv', columns=features, index_label='id')\n",
    "test_private.to_csv('track1_test_private.csv', columns=features, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11h 9min 31s, sys: 1min 33s, total: 11h 11min 4s\n",
      "Wall time: 3h 48min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "types = dict(zip(features+['id', 'label', 'weight'], repeat(np.float32)))\n",
    "types['id'] = np.int64\n",
    "types['label'] = np.int64\n",
    "\n",
    "train = pd.read_csv('track1_train.csv',\n",
    "                    usecols = features + ['id', 'label', 'weight'], index_col='id', dtype=types)\n",
    "\n",
    "test_public = pd.read_csv('track1_test_public.csv',\n",
    "                          usecols = features + ['id'], index_col='id', dtype=types)\n",
    "\n",
    "test_private = pd.read_csv('track1_test_private.csv',\n",
    "                           usecols = features + ['id'], index_col='id', dtype=types)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "\n",
    "model = xgboost.XGBClassifier(n_jobs=3, random_state=0, **xgb_params)    \n",
    "model.fit(train[features].values, train.label.values, sample_weight=train.weight.values)\n",
    "model.save_model(f\"track1.xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_public = model.predict_proba(test_public[features].values)[:, 1]\n",
    "pd.DataFrame(data={\"prediction\": predictions_public}, index=test_public.index).to_csv(\n",
    "    f\"track1_public.csv\", index_label='id', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_private = model.predict_proba(test_private[features].values)[:, 1]\n",
    "pd.DataFrame(data={\"prediction\": predictions_private}, index=test_private.index).to_csv(\n",
    "    f\"track1_private.csv\", index_label='id', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Track2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'NShared', 'PT', 'Delta_D_norm[3]', 'Delta_X_norm[1]', 'Delta_D_norm[0]',\n",
    "    'FOI_hits_N', 'Delta_X_norm[3]', 'Delta_D_norm[2]', 'MatchedHit_TYPE[1]',\n",
    "    'Delta_D_norm[1]', 'ncl[2]', 'P', 'Delta_X_norm[0]'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 2.78 s, total: 1min 25s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_features_fast(sample):\n",
    "    # отклонение координат\n",
    "    for stage in [0,1,2,3]:\n",
    "        sample[f'Delta_X[{stage}]'] = sample[f'MatchedHit_X[{stage}]'] - sample[f'Lextra_X[{stage}]']\n",
    "\n",
    "    # нормированное отклонение координат            \n",
    "    for stage in [0,1,3]:\n",
    "        sample[f'Delta_X_norm[{stage}]'] = (sample[f'Delta_X[{stage}]'].abs()/\n",
    "                                            np.sqrt(sample[f'MatchedHit_DX[{stage}]']**2 + sample[f'Mextra_DX2[{stage}]']))\n",
    "\n",
    "    # расстояние\n",
    "    for stage in [0,1,2,3]:\n",
    "        sample[f'Delta_D_norm[{stage}]'] = (np.sqrt(sample[f'Delta_X[{stage}]']**2 + (sample[f'MatchedHit_Y[{stage}]'] - sample[f'Lextra_Y[{stage}]'])**2)/\n",
    "                                            np.sqrt(sample[f'MatchedHit_DX[{stage}]']**2 + sample[f'MatchedHit_DY[{stage}]']**2 + sample[f'Mextra_DX2[{stage}]'] + sample[f'Mextra_DY2[{stage}]']))\n",
    "\n",
    "        \n",
    "types = dict(zip(SIMPLE_FEATURE_COLUMNS+['weight'], repeat(np.float32)))\n",
    "types['id'] = np.int64\n",
    "types['label'] = np.int64\n",
    "        \n",
    "train = pd.concat([\n",
    "    pd.read_csv(os.path.join(DATA_PATH, \"train_part_%i.csv.gz\" % i),\n",
    "                usecols = SIMPLE_FEATURE_COLUMNS + ['id', 'label', 'weight'],\n",
    "                index_col='id', dtype=types)\n",
    "    for i in (1,2)], axis=0, ignore_index=True)\n",
    "\n",
    "test_public = pd.read_csv(os.path.join(DATA_PATH, \"test_public.csv.gz\"),\n",
    "                          usecols = SIMPLE_FEATURE_COLUMNS + ['id'],  \n",
    "                          index_col='id', dtype=types)\n",
    "\n",
    "# test_private = pd.read_csv(os.path.join(DATA_PATH, 'test_private_v3_track_2.csv.gz'),\n",
    "#                            usecols = SIMPLE_FEATURE_COLUMNS + ['id'],\n",
    "#                            index_col='id', dtype=types)\n",
    "\n",
    "build_features_fast(train)\n",
    "build_features_fast(test_public)\n",
    "# build_features_fast(test_private)\n",
    "\n",
    "train.to_csv('track2_train.csv', columns=features+['label', 'weight'], index_label='id')\n",
    "test_public.to_csv('track2_test_public.csv', columns=features, index_label='id')\n",
    "#test_private.to_csv('track2_test_private.csv', columns=features, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.731123685836792\n",
      "CPU times: user 3min 36s, sys: 25.7 s, total: 4min 1s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "types = dict(zip(features+['id', 'label', 'weight'], repeat(np.float32)))\n",
    "types['id'] = np.int64\n",
    "types['label'] = np.int64\n",
    "\n",
    "train = pd.read_csv('track2_train.csv',\n",
    "                    usecols = features + ['id', 'label', 'weight'], index_col='id', dtype=types)\n",
    "\n",
    "test_public = pd.read_csv('track2_test_public.csv',\n",
    "                          usecols = features + ['id'], index_col='id', dtype=types)\n",
    "\n",
    "# test_private = pd.read_csv('track2_test_private.csv',\n",
    "#                            usecols = features + ['id'], index_col='id', dtype=types)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 20,\n",
    "}\n",
    "\n",
    "train_part, validation = train_test_split(train, test_size=0.25, shuffle=True, random_state=0)\n",
    "\n",
    "model = xgboost.XGBClassifier(n_jobs=-1, random_state=0, **xgb_params)    \n",
    "model.fit(train_part[features].values, train_part.label.values, sample_weight=train_part.weight.values)\n",
    "validation_predictions = model.predict_proba(validation[features].values)[:, 1]\n",
    "score = scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values)\n",
    "print(f'score={score}')\n",
    "\n",
    "predictions_public = model.predict_proba(test_public[features].values)[:, 1]\n",
    "pd.DataFrame(data={\"prediction\": predictions_public}, index=test_public.index).to_csv(\n",
    "    f\"track2_public.csv\", index_label='id')\n",
    "\n",
    "model.save_model(f\"track2.xgb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "42px",
    "width": "190px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
